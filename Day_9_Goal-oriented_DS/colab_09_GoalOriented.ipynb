{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCdNRLuY1lSP"
   },
   "source": [
    "# shorturl.at/iOY35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2POVHVpWnlb"
   },
   "source": [
    "Основано на: https://github.com/DanAnastasyev/DeepNLP-Course Week 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4WlMyJVRkzQ",
    "outputId": "4fa6217f-863d-4be7-d7fd-aa558be058dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SlotGated-SLU'...\n",
      "remote: Enumerating objects: 51, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 51 (delta 4), reused 2 (delta 2), pack-reused 44\u001b[K\n",
      "Unpacking objects: 100% (51/51), 426.19 KiB | 3.77 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
    "!wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OC8_EccZx2Zg",
    "outputId": "ed8133f0-24b7-4e5d-a74d-fde50497883b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.6.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.4.0) (3.4)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu118\n",
      "    Uninstalling torch-2.0.0+cu118:\n",
      "      Successfully uninstalled torch-2.0.0+cu118\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.15.1\n",
      "    Uninstalling torchtext-0.15.1:\n",
      "      Successfully uninstalled torchtext-0.15.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchtext-0.4.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchtext==0.10.0\n",
    "!pip install  torchtext==0.4.0 torch==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UvJKy3mtVOpw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QR5dTAfVhLD"
   },
   "source": [
    "# Диалоговые системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fox5ub_GKSLL"
   },
   "source": [
    "Диалоговые системы делятся на два типа - *goal-orientied* и *general conversation*.\n",
    "\n",
    "**General conversation** - это болталка, разговор на свободную тему:  \n",
    "<img src=\"https://i.ibb.co/bFwwGpc/alice.jpg\" width=\"200\"/>\n",
    "\n",
    "Сегодня будем говорить не про них, а про **goal-orientied** системы:\n",
    "\n",
    "<img src=\"https://hsto.org/webt/gj/3y/xl/gj3yxlqbr7ujuqr9r2akacxmkee.jpeg\" width=\"600\"/>\n",
    "\n",
    "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
    "\n",
    "Пользователь говорит что-то, это что-то распознается. По распознанному определяется - что, где и когда он хотел. Дальше диалоговый движок решает, действительно ли пользователь знает, чего хотел попросить. Происходит поход в источники - узнать информацию, которую (кажется) запросил пользователь. Исходя из всего этого генерируется некоторый ответ:\n",
    "\n",
    "<img src=\"https://i.ibb.co/8XcdpJ7/goal-orientied.png\" width=\"600\"/>\n",
    "\n",
    "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
    "\n",
    "Будем учить ту часть, которая посередине - классификатор и теггер. Всё остальное обычно - эвристики и захардкоженные ответы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIJt4hPLPYtO"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUZ8xjG_PT7C"
   },
   "source": [
    "Есть условно стандартный датасет - atis, который неприлично маленький, на самом деле.\n",
    "\n",
    "К нему можно взять еще датасет snips - он больше и разнообразнее.\n",
    "\n",
    "Оба датасета возьмем из репозитория статьи [Slot-Gated Modeling for Joint Slot Filling and Intent Prediction](http://aclweb.org/anthology/N18-2118).\n",
    "\n",
    "Начнем с atis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yw_FnOVOVgdX"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
    "         open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
    "         open(os.path.join(path, 'label')) as f_intents:\n",
    "        \n",
    "        return [  (words.strip().split(), tags.strip().split(), intent.strip()) \n",
    "                  for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JrAgjAFVWnh9"
   },
   "outputs": [],
   "source": [
    "train_data = read_dataset('SlotGated-SLU/data/atis/train/')\n",
    "val_data = read_dataset('SlotGated-SLU/data/atis/valid/')\n",
    "test_data = read_dataset('SlotGated-SLU/data/atis/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3zvT5BsWv0p",
    "outputId": "10571dc8-b690-4bfb-bf63-31a682acea4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent:\t atis_flight\n",
      "Text:\t is\tthere\ta\tdelta\tflight\tfrom\tdenver\tto\tsan\tfrancisco\n",
      "Tags:\t O\tO\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_airfare\n",
      "Text:\t what\tis\tthe\tmost\texpensive\tone\tway\tfare\tfrom\tboston\tto\tatlanta\ton\tamerican\tairlines\n",
      "Tags:\t O\tO\tO\tB-cost_relative\tI-cost_relative\tB-round_trip\tI-round_trip\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\n",
      "\n",
      "Intent:\t atis_airline\n",
      "Text:\t list\tairlines\tserving\tbetween\tdenver\tand\tsan\tfrancisco\n",
      "Tags:\t O\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_ground_service\n",
      "Text:\t tell\tme\tabout\tground\ttransportation\tbetween\torlando\tinternational\tand\torlando\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_quantity\n",
      "Text:\t how\tmany\tairlines\thave\tflights\twith\tservice\tclass\tyn\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-fare_basis_code\n",
      "\n",
      "Intent:\t atis_city\n",
      "Text:\t where\tis\tlester\tpearson\tairport\n",
      "Tags:\t O\tO\tB-airport_name\tI-airport_name\tI-airport_name\n",
      "\n",
      "Intent:\t atis_flight#atis_airfare\n",
      "Text:\t all\tflights\tand\tfares\tfrom\tatlanta\tto\tdallas\tround\ttrip\tafter\t12\tpm\tless\tthan\t1100\tdollars\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tB-round_trip\tI-round_trip\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tB-cost_relative\tO\tB-fare_amount\tI-fare_amount\n",
      "\n",
      "Intent:\t atis_abbreviation\n",
      "Text:\t what\tis\tfare\tcode\tm\n",
      "Tags:\t O\tO\tO\tO\tB-fare_basis_code\n",
      "\n",
      "Intent:\t atis_aircraft\n",
      "Text:\t i\twant\tto\tgo\tand\ttake\ta\tplane\tin\tatlanta\tand\tfly\tto\tboston\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tO\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_distance\n",
      "Text:\t how\tfar\tis\tit\tfrom\torlando\tairport\tto\torlando\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_ground_fare\n",
      "Text:\t what\tare\tthe\trental\tcar\trates\tin\tdallas\n",
      "Tags:\t O\tO\tO\tB-transport_type\tI-transport_type\tO\tO\tB-city_name\n",
      "\n",
      "Intent:\t atis_capacity\n",
      "Text:\t what\tis\tthe\tseating\tcapacity\tof\ta\tboeing\t767\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-aircraft_code\n",
      "\n",
      "Intent:\t atis_flight_time\n",
      "Text:\t what\ttimes\tdoes\tcontinental\tdepart\tfrom\tboston\tto\tsan\tfrancisco\n",
      "Tags:\t O\tB-flight_time\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_meal\n",
      "Text:\t what\tare\tall\tthe\tavailable\tmeals\n",
      "Tags:\t O\tO\tO\tO\tO\tB-meal\n",
      "\n",
      "Intent:\t atis_aircraft#atis_flight#atis_flight_no\n",
      "Text:\t i\twant\tto\tfly\tfrom\tdetroit\tto\tst.\tpetersburg\ton\tnorthwest\tairlines\tand\tleave\taround\t9\tam\ttell\tme\twhat\taircraft\tare\tused\tby\tthis\tflight\tand\ttell\tme\tthe\tflight\tnumber\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n",
      "Intent:\t atis_flight_no\n",
      "Text:\t i'm\ttrying\tto\tfind\tthe\tflight\tnumber\tfrom\ta\tflight\tfrom\torlando\tto\tcleveland\ton\tus\tair\tand\tit\tarrives\taround\t10\tpm\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tO\tB-arrive_time.time_relative\tB-arrive_time.time\tI-arrive_time.time\n",
      "\n",
      "Intent:\t atis_restriction\n",
      "Text:\t what\tis\trestriction\tap80\n",
      "Tags:\t O\tO\tO\tB-restriction_code\n",
      "\n",
      "Intent:\t atis_airport\n",
      "Text:\t what's\tthe\tname\tof\tthe\tdenver\tairport\n",
      "Tags:\t O\tO\tO\tO\tO\tB-airport_name\tI-airport_name\n",
      "\n",
      "Intent:\t atis_airline#atis_flight_no\n",
      "Text:\t airline\tand\tflight\tnumber\tfrom\tcolumbus\tto\tminneapolis\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_cheapest\n",
      "Text:\t show\tme\tthe\tcheapest\tfare\tin\tthe\tdatabase\n",
      "Tags:\t O\tO\tO\tB-cost_relative\tO\tO\tO\tO\n",
      "\n",
      "Intent:\t atis_ground_service#atis_ground_fare\n",
      "Text:\t what\tground\ttransportation\tis\tavailable\tfrom\tthe\tpittsburgh\tairport\tto\tdowntown\tand\thow\tmuch\tdoes\tit\tcost\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intent_to_example = {example[2]: example for example in train_data}\n",
    "for example in intent_to_example.values():\n",
    "    print('Intent:\\t', example[2])\n",
    "    print('Text:\\t', '\\t'.join(example[0]))\n",
    "    print('Tags:\\t', '\\t'.join(example[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EoT_us7Y23P",
    "outputId": "6c506ab1-e3d6-4669-ae3c-b86f0abf1bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 869\n",
      "Tags count = 128\n",
      "Intents count = 26\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "tokens_field = Field()\n",
    "tags_field = Field(unk_token=None)\n",
    "intent_field = LabelField()\n",
    "\n",
    "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
    "\n",
    "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
    "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
    "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
    "# ВНИМАНИЕ - КОСТЫЛЬ\n",
    "all_dataset = Dataset([Example.fromlist(example, fields) for example in train_data+val_data+test_data], fields)\n",
    "\n",
    "tokens_field.build_vocab(train_dataset)\n",
    "tags_field.build_vocab(all_dataset)\n",
    "intent_field.build_vocab(all_dataset)\n",
    "\n",
    "print('Vocab size =', len(tokens_field.vocab))\n",
    "print('Tags count =', len(tags_field.vocab))\n",
    "print('Intents count =', len(intent_field.vocab))\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
    "    shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPOfmYA6as2M"
   },
   "source": [
    "То же самое со snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bofp6semFwvG",
    "outputId": "6f87c92a-d79a-455d-e98f-b18c892e6331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent:\t PlayMusic\n",
      "Text:\t play\tfunky\theavy\tbluesy\n",
      "Tags:\t O\tB-playlist\tI-playlist\tI-playlist\n",
      "\n",
      "Intent:\t AddToPlaylist\n",
      "Text:\t add\tgabrial\tmcnair\tto\tmy\tlove\tin\tparis\tlist\n",
      "Tags:\t O\tB-artist\tI-artist\tO\tB-playlist_owner\tB-playlist\tI-playlist\tI-playlist\tO\n",
      "\n",
      "Intent:\t RateBook\n",
      "Text:\t rate\trichard\tcarvel\t4\tout\tof\t6\n",
      "Tags:\t O\tB-object_name\tI-object_name\tB-rating_value\tO\tO\tB-best_rating\n",
      "\n",
      "Intent:\t SearchScreeningEvent\n",
      "Text:\t can\ti\tget\tthe\tmovie\tschedule\tfor\tloews\tcineplex\tentertainment\n",
      "Tags:\t O\tO\tO\tO\tB-object_type\tI-object_type\tO\tB-location_name\tI-location_name\tI-location_name\n",
      "\n",
      "Intent:\t BookRestaurant\n",
      "Text:\t i\twant\tto\teat\tchoucroute\tat\ta\tbrasserie\tfor\t8\n",
      "Tags:\t O\tO\tO\tO\tB-served_dish\tO\tO\tB-restaurant_type\tO\tB-party_size_number\n",
      "\n",
      "Intent:\t GetWeather\n",
      "Text:\t tell\tme\twhen\tit\tll\tbe\tchillier\tin\tcavalero\tcorner\tid\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tB-condition_temperature\tO\tB-city\tI-city\tB-state\n",
      "\n",
      "Intent:\t SearchCreativeWork\n",
      "Text:\t go\tto\tthe\tphotograph\tthe\tinflated\ttear\n",
      "Tags:\t O\tO\tO\tB-object_type\tB-object_name\tI-object_name\tI-object_name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snips_train_data = read_dataset('SlotGated-SLU/data/snips/train/')\n",
    "snips_val_data = read_dataset('SlotGated-SLU/data/snips/valid/')\n",
    "snips_test_data = read_dataset('SlotGated-SLU/data/snips/test/')\n",
    "snips_intent_to_example = {example[2]: example for example in snips_train_data}\n",
    "for example in snips_intent_to_example.values():\n",
    "    print('Intent:\\t', example[2])\n",
    "    print('Text:\\t', '\\t'.join(example[0]))\n",
    "    print('Tags:\\t', '\\t'.join(example[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgoZ7sZSGQsC",
    "outputId": "c073bdf0-585e-4a89-8f38-4f72988a8b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 11420\n",
      "Tags count = 73\n",
      "Intents count = 7\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "snips_tokens_field = Field()\n",
    "snips_tags_field = Field(unk_token=None)\n",
    "snips_intent_field = LabelField()\n",
    "\n",
    "fields = [('tokens', snips_tokens_field), ('tags', snips_tags_field), ('intent', snips_intent_field)]\n",
    "\n",
    "snips_train_dataset = Dataset([Example.fromlist(example, fields) for example in snips_train_data], fields)\n",
    "snips_val_dataset = Dataset([Example.fromlist(example, fields) for example in snips_val_data], fields)\n",
    "snips_test_dataset = Dataset([Example.fromlist(example, fields) for example in snips_test_data], fields)\n",
    "# ВНИМАНИЕ - КОСТЫЛЬ\n",
    "snips_all_dataset = Dataset([Example.fromlist(example, fields) for example in snips_train_data+snips_val_data+snips_test_data], fields)\n",
    "\n",
    "snips_tokens_field.build_vocab(snips_train_dataset)\n",
    "snips_tags_field.build_vocab(snips_all_dataset)\n",
    "snips_intent_field.build_vocab(snips_all_dataset)\n",
    "\n",
    "print('Vocab size =', len(snips_tokens_field.vocab))\n",
    "print('Tags count =', len(snips_tags_field.vocab))\n",
    "print('Intents count =', len(snips_intent_field.vocab))\n",
    "\n",
    "snips_train_iter, snips_val_iter, snips_test_iter = BucketIterator.splits(\n",
    "    datasets=(snips_train_dataset, snips_val_dataset, snips_test_dataset), batch_sizes=(32, 128, 128), \n",
    "    shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx8tY7_xQIpi"
   },
   "source": [
    "## Классификатор интентов\n",
    "\n",
    "Начнем с классификатора: к какому интенту относится данный запрос.\n",
    "\n",
    "Ничего умного - берём rnn'ку и учимся предсказывать метки-интенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u4pZR9IRckK-"
   },
   "outputs": [],
   "source": [
    "class IntentClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, emb_dim=64,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm_layer = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True,\n",
    "                                  bidirectional=True, num_layers=num_layers)\n",
    "        self.out_layer = nn.Linear(lstm_hidden_dim * 2, intents_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings_layer(inputs)\n",
    "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
    "        output, (final_hidden_state, _) = self.lstm_layer(projections)\n",
    "        hidden = self.dropout(torch.cat((final_hidden_state[0], final_hidden_state[1]), dim=1))\n",
    "        output = self.out_layer.forward(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MfKFMfeg_RLV"
   },
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self, model, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        self.epoch_loss = 0\n",
    "        self.correct_count, self.total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        logits = self.model(batch.tokens.transpose(0, 1))\n",
    "        loss = self.criterion(logits, batch.intent)\n",
    "        predicted_intent = torch.max(logits, axis=1)[1]\n",
    "        self.total_count += predicted_intent.size(0)\n",
    "        self.correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
    "        if self.is_train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IqCvQEByddtj"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "def do_epoch(trainer, data_iter, is_train, name=None):\n",
    "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):\n",
    "                batch_progress = trainer.on_batch(batch)\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(batch_progress)\n",
    "                \n",
    "            epoch_progress = trainer.on_epoch_end()\n",
    "            progress_bar.set_description(epoch_progress)\n",
    "            progress_bar.refresh()\n",
    "          \n",
    "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQBsP8SHhjqm"
   },
   "outputs": [],
   "source": [
    "model = IntentClassifierModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = ModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpWXjnsRWg4r",
    "outputId": "5869717d-a86a-456a-9b04-04b8a8880f5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:00<00:00, 102.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 107.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.34127, Accuracy = 95.07%: 100%|██████████| 7/7 [00:00<00:00, 103.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.34127, Accuracy = 95.07%: 100%|██████████| 7/7 [00:00<00:00, 94.32it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zsAJJCEQ8Ti"
   },
   "source": [
    "## Теггер\n",
    "\n",
    "![](https://commons.bmstu.wiki/images/0/00/NER1.png)  \n",
    "*From [NER](https://ru.bmstu.wiki/NER_(Named-Entity_Recognition)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUZ1Wmw1a-Qo"
   },
   "source": [
    "#### **Задание 1.1**\n",
    "Напишите простой теггер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwphVxmdkChy"
   },
   "outputs": [],
   "source": [
    "class TokenTaggerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tags_count, emb_dim=64,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*lstm_hidden_dim, tags_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # YOUR CODE HERE\n",
    "        emb = self.embedding(inputs)\n",
    "        drp = self.dropout(emb)\n",
    "        output, (hidden_state, _) = self.lstm(drp)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mzyxM0502wy"
   },
   "source": [
    "#### **Задание 1.2**\n",
    "Обновите `ModelTrainer`: считать нужно всё те же лосс и accuracy, только теперь немного по-другому."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMRwby_NnyvJ"
   },
   "outputs": [],
   "source": [
    "class TagModelTrainer():\n",
    "    def __init__(self, model, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        self.epoch_loss = 0\n",
    "        self.correct_count, self.total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        # YOUR CODE HERE\n",
    "        logits = self.model(batch.tokens.transpose(0, 1))\n",
    "        true_tags = batch.tags.transpose(0, 1)\n",
    "        loss = self.criterion(logits.transpose(1, 2), true_tags)\n",
    "        predicted_tags = torch.max(logits, axis=2).indices\n",
    "        self.total_count += torch.sum(true_tags!=0).item()\n",
    "        self.correct_count += torch.sum(predicted_tags==true_tags).item() - torch.sum(true_tags==0).item()\n",
    "\n",
    "        if self.is_train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QXaapt3nuF_",
    "outputId": "465710c4-40d1-4000-f40a-a43599cd2e78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 1.04754, Accuracy = 62.38%: 100%|██████████| 140/140 [00:01<00:00, 105.89it/s]\n",
      "[1 / 30]   Val: Loss = 0.33551, Accuracy = 81.24%: 100%|██████████| 4/4 [00:00<00:00, 74.61it/s]\n",
      "[2 / 30] Train: Loss = 0.29538, Accuracy = 87.20%: 100%|██████████| 140/140 [00:01<00:00, 110.59it/s]\n",
      "[2 / 30]   Val: Loss = 0.15431, Accuracy = 90.79%: 100%|██████████| 4/4 [00:00<00:00, 89.36it/s]\n",
      "[3 / 30] Train: Loss = 0.15983, Accuracy = 93.01%: 100%|██████████| 140/140 [00:01<00:00, 136.55it/s]\n",
      "[3 / 30]   Val: Loss = 0.10306, Accuracy = 94.04%: 100%|██████████| 4/4 [00:00<00:00, 80.78it/s]\n",
      "[4 / 30] Train: Loss = 0.10893, Accuracy = 95.20%: 100%|██████████| 140/140 [00:01<00:00, 129.69it/s]\n",
      "[4 / 30]   Val: Loss = 0.06965, Accuracy = 95.49%: 100%|██████████| 4/4 [00:00<00:00, 86.47it/s]\n",
      "[5 / 30] Train: Loss = 0.07767, Accuracy = 96.53%: 100%|██████████| 140/140 [00:01<00:00, 136.17it/s]\n",
      "[5 / 30]   Val: Loss = 0.06755, Accuracy = 96.12%: 100%|██████████| 4/4 [00:00<00:00, 88.43it/s] \n",
      "[6 / 30] Train: Loss = 0.06114, Accuracy = 97.38%: 100%|██████████| 140/140 [00:01<00:00, 131.05it/s]\n",
      "[6 / 30]   Val: Loss = 0.04862, Accuracy = 96.90%: 100%|██████████| 4/4 [00:00<00:00, 86.84it/s]\n",
      "[7 / 30] Train: Loss = 0.04989, Accuracy = 97.78%: 100%|██████████| 140/140 [00:01<00:00, 126.66it/s]\n",
      "[7 / 30]   Val: Loss = 0.04822, Accuracy = 97.28%: 100%|██████████| 4/4 [00:00<00:00, 88.61it/s]\n",
      "[8 / 30] Train: Loss = 0.04078, Accuracy = 98.19%: 100%|██████████| 140/140 [00:01<00:00, 131.26it/s]\n",
      "[8 / 30]   Val: Loss = 0.04151, Accuracy = 97.56%: 100%|██████████| 4/4 [00:00<00:00, 90.28it/s]\n",
      "[9 / 30] Train: Loss = 0.03369, Accuracy = 98.51%: 100%|██████████| 140/140 [00:01<00:00, 127.42it/s]\n",
      "[9 / 30]   Val: Loss = 0.03288, Accuracy = 97.81%: 100%|██████████| 4/4 [00:00<00:00, 83.04it/s]\n",
      "[10 / 30] Train: Loss = 0.02848, Accuracy = 98.72%: 100%|██████████| 140/140 [00:01<00:00, 129.77it/s]\n",
      "[10 / 30]   Val: Loss = 0.03100, Accuracy = 97.91%: 100%|██████████| 4/4 [00:00<00:00, 90.55it/s]\n",
      "[11 / 30] Train: Loss = 0.02405, Accuracy = 98.91%: 100%|██████████| 140/140 [00:01<00:00, 114.34it/s]\n",
      "[11 / 30]   Val: Loss = 0.03004, Accuracy = 98.16%: 100%|██████████| 4/4 [00:00<00:00, 85.59it/s]\n",
      "[12 / 30] Train: Loss = 0.02017, Accuracy = 99.06%: 100%|██████████| 140/140 [00:01<00:00, 108.48it/s]\n",
      "[12 / 30]   Val: Loss = 0.02890, Accuracy = 98.14%: 100%|██████████| 4/4 [00:00<00:00, 76.20it/s]\n",
      "[13 / 30] Train: Loss = 0.01718, Accuracy = 99.18%: 100%|██████████| 140/140 [00:01<00:00, 105.54it/s]\n",
      "[13 / 30]   Val: Loss = 0.02905, Accuracy = 98.35%: 100%|██████████| 4/4 [00:00<00:00, 82.81it/s]\n",
      "[14 / 30] Train: Loss = 0.01517, Accuracy = 99.29%: 100%|██████████| 140/140 [00:01<00:00, 123.66it/s]\n",
      "[14 / 30]   Val: Loss = 0.02891, Accuracy = 98.26%: 100%|██████████| 4/4 [00:00<00:00, 84.44it/s]\n",
      "[15 / 30] Train: Loss = 0.01282, Accuracy = 99.37%: 100%|██████████| 140/140 [00:01<00:00, 128.29it/s]\n",
      "[15 / 30]   Val: Loss = 0.02482, Accuracy = 98.51%: 100%|██████████| 4/4 [00:00<00:00, 81.58it/s]\n",
      "[16 / 30] Train: Loss = 0.01141, Accuracy = 99.48%: 100%|██████████| 140/140 [00:01<00:00, 131.75it/s]\n",
      "[16 / 30]   Val: Loss = 0.02508, Accuracy = 98.49%: 100%|██████████| 4/4 [00:00<00:00, 91.77it/s]\n",
      "[17 / 30] Train: Loss = 0.00998, Accuracy = 99.53%: 100%|██████████| 140/140 [00:01<00:00, 128.80it/s]\n",
      "[17 / 30]   Val: Loss = 0.02442, Accuracy = 98.63%: 100%|██████████| 4/4 [00:00<00:00, 93.92it/s]\n",
      "[18 / 30] Train: Loss = 0.00895, Accuracy = 99.60%: 100%|██████████| 140/140 [00:01<00:00, 132.80it/s]\n",
      "[18 / 30]   Val: Loss = 0.02346, Accuracy = 98.51%: 100%|██████████| 4/4 [00:00<00:00, 92.74it/s]\n",
      "[19 / 30] Train: Loss = 0.00741, Accuracy = 99.68%: 100%|██████████| 140/140 [00:01<00:00, 121.99it/s]\n",
      "[19 / 30]   Val: Loss = 0.02294, Accuracy = 98.65%: 100%|██████████| 4/4 [00:00<00:00, 90.62it/s]\n",
      "[20 / 30] Train: Loss = 0.00686, Accuracy = 99.71%: 100%|██████████| 140/140 [00:01<00:00, 129.31it/s]\n",
      "[20 / 30]   Val: Loss = 0.02332, Accuracy = 98.65%: 100%|██████████| 4/4 [00:00<00:00, 92.06it/s]\n",
      "[21 / 30] Train: Loss = 0.00617, Accuracy = 99.74%: 100%|██████████| 140/140 [00:01<00:00, 122.67it/s]\n",
      "[21 / 30]   Val: Loss = 0.02336, Accuracy = 98.68%: 100%|██████████| 4/4 [00:00<00:00, 91.17it/s]\n",
      "[22 / 30] Train: Loss = 0.00597, Accuracy = 99.75%: 100%|██████████| 140/140 [00:01<00:00, 120.70it/s]\n",
      "[22 / 30]   Val: Loss = 0.02165, Accuracy = 98.70%: 100%|██████████| 4/4 [00:00<00:00, 68.42it/s]\n",
      "[23 / 30] Train: Loss = 0.00517, Accuracy = 99.77%: 100%|██████████| 140/140 [00:01<00:00, 113.00it/s]\n",
      "[23 / 30]   Val: Loss = 0.02316, Accuracy = 98.63%: 100%|██████████| 4/4 [00:00<00:00, 90.32it/s]\n",
      "[24 / 30] Train: Loss = 0.00426, Accuracy = 99.84%: 100%|██████████| 140/140 [00:01<00:00, 101.63it/s]\n",
      "[24 / 30]   Val: Loss = 0.02305, Accuracy = 98.76%: 100%|██████████| 4/4 [00:00<00:00, 77.11it/s]\n",
      "[25 / 30] Train: Loss = 0.00419, Accuracy = 99.84%: 100%|██████████| 140/140 [00:01<00:00, 108.32it/s]\n",
      "[25 / 30]   Val: Loss = 0.02226, Accuracy = 98.70%: 100%|██████████| 4/4 [00:00<00:00, 88.62it/s]\n",
      "[26 / 30] Train: Loss = 0.00413, Accuracy = 99.82%: 100%|██████████| 140/140 [00:01<00:00, 126.12it/s]\n",
      "[26 / 30]   Val: Loss = 0.02236, Accuracy = 98.63%: 100%|██████████| 4/4 [00:00<00:00, 92.60it/s]\n",
      "[27 / 30] Train: Loss = 0.00456, Accuracy = 99.80%: 100%|██████████| 140/140 [00:01<00:00, 125.30it/s]\n",
      "[27 / 30]   Val: Loss = 0.02340, Accuracy = 98.72%: 100%|██████████| 4/4 [00:00<00:00, 85.96it/s]\n",
      "[28 / 30] Train: Loss = 0.00342, Accuracy = 99.86%: 100%|██████████| 140/140 [00:01<00:00, 126.56it/s]\n",
      "[28 / 30]   Val: Loss = 0.02446, Accuracy = 98.67%: 100%|██████████| 4/4 [00:00<00:00, 81.63it/s]\n",
      "[29 / 30] Train: Loss = 0.00328, Accuracy = 99.87%: 100%|██████████| 140/140 [00:01<00:00, 125.14it/s]\n",
      "[29 / 30]   Val: Loss = 0.02305, Accuracy = 98.70%: 100%|██████████| 4/4 [00:00<00:00, 90.38it/s]\n",
      "[30 / 30] Train: Loss = 0.00309, Accuracy = 99.88%: 100%|██████████| 140/140 [00:01<00:00, 124.60it/s]\n",
      "[30 / 30]   Val: Loss = 0.02546, Accuracy = 98.77%: 100%|██████████| 4/4 [00:00<00:00, 93.96it/s]\n"
     ]
    }
   ],
   "source": [
    "model = TokenTaggerModel(vocab_size=len(tokens_field.vocab), tags_count=len(tags_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = TagModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6spi0nfWA6uK",
    "outputId": "00b9fe5e-8a99-4325-c027-efaf8ff7f1fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.07067, Accuracy = 97.58%: 100%|██████████| 7/7 [00:00<00:00, 101.55it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKeXWjs7pE35",
    "outputId": "33d2b56c-1511-438d-f3da-0f6bae525302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 94.12%, Recall = 94.71%, F1 = 94.41%\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "def eval_tagger(model, test_iter):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iter:\n",
    "            pred = model.forward(batch.tokens.transpose(0, 1)).transpose(1, 2).max(dim=1)[1].cpu().tolist()\n",
    "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
    "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in batch.tags.transpose(0, 1).cpu().tolist()])\n",
    "\n",
    "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
    "\n",
    "eval_tagger(model, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APcntGZ0ReXl"
   },
   "source": [
    "## Multi-task learning\n",
    "\n",
    "Реализуем модель, которая умеет сразу и предсказывать теги и интенты. Идея в том, что в этом всем есть общая информация, которая должна помочь как одной, так и другой задаче: зная интент, можно понять, какие слоты вообще могут быть, а зная слоты, можно угадать и интент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkWuh_QMbeOM"
   },
   "source": [
    "#### **Задание 2.1**\n",
    "Реализуйте объединенную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goLcDk-Tu0uM"
   },
   "outputs": [],
   "source": [
    "class SharedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=64,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.intent_linear = nn.Linear(2*lstm_hidden_dim, intents_count)\n",
    "        self.tags_linear = nn.Linear(2*lstm_hidden_dim, tags_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # YOUR CODE HERE\n",
    "        emb = self.embedding(inputs)\n",
    "        drp = self.dropout(emb)\n",
    "        otp, (hidden_state, _) = self.lstm(drp)\n",
    "        hid = torch.cat((hidden_state[0], hidden_state[1]), dim=1)\n",
    "        tag_output = self.tags_linear(otp)\n",
    "        intent_output = self.intent_linear(hid)\n",
    "        return tag_output, intent_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz2A9hHybrWZ"
   },
   "source": [
    "#### **Задание 2.2**\n",
    "Допишите SharedModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5semraSfv56f"
   },
   "outputs": [],
   "source": [
    "class SharedModelTrainer():\n",
    "    def __init__(self, model, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        self.epoch_loss = 0\n",
    "        self.tag_correct_count, self.tag_total_count = 0, 0\n",
    "        self.intent_correct_count, self.intent_total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        return '{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.tag_correct_count / self.tag_total_count, \n",
    "            self.intent_correct_count / self.intent_total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        # YOUR CODE HERE\n",
    "        tag_logits, int_logits = self.model(batch.tokens.transpose(0, 1))\n",
    "        #tag\n",
    "        tag_true = batch.tags.transpose(0, 1)\n",
    "        tag_loss = self.criterion(tag_logits.transpose(1, 2), tag_true)\n",
    "        tag_predict = torch.max(tag_logits, axis=2).indices\n",
    "        predicted_tags = torch.max(tag_logits, axis=2).indices\n",
    "        self.tag_total_count += torch.sum(tag_true!=0).item()\n",
    "        self.tag_correct_count += torch.sum(predicted_tags==tag_true).item() - torch.sum(tag_true==0).item()\n",
    "        #int\n",
    "        int_true = batch.intent\n",
    "        int_loss = self.criterion(int_logits, int_true)\n",
    "        predicted_intent = torch.max(int_logits, axis=1)[1]\n",
    "        self.intent_total_count += predicted_intent.size(0)\n",
    "        self.intent_correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
    "        #common\n",
    "        loss = tag_loss + int_loss\n",
    "\n",
    "        if self.is_train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BP4b-4zxU0v",
    "outputId": "3e848b02-eba8-4272-fe7f-67ed5e620a7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 2.20143, Tags accuracy = 59.99%, Intents accuracy = 74.90%: 100%|██████████| 140/140 [00:01<00:00, 123.17it/s]\n",
      "[1 / 30]   Val: Loss = 1.19105, Tags accuracy = 77.42%, Intents accuracy = 79.40%: 100%|██████████| 4/4 [00:00<00:00, 92.32it/s]\n",
      "[2 / 30] Train: Loss = 0.94203, Tags accuracy = 82.74%, Intents accuracy = 86.69%: 100%|██████████| 140/140 [00:01<00:00, 106.33it/s]\n",
      "[2 / 30]   Val: Loss = 0.75952, Tags accuracy = 87.85%, Intents accuracy = 87.00%: 100%|██████████| 4/4 [00:00<00:00, 82.08it/s]\n",
      "[3 / 30] Train: Loss = 0.60574, Tags accuracy = 89.92%, Intents accuracy = 90.78%: 100%|██████████| 140/140 [00:01<00:00, 99.58it/s] \n",
      "[3 / 30]   Val: Loss = 0.57435, Tags accuracy = 91.81%, Intents accuracy = 89.80%: 100%|██████████| 4/4 [00:00<00:00, 62.69it/s]\n",
      "[4 / 30] Train: Loss = 0.45551, Tags accuracy = 92.89%, Intents accuracy = 92.32%: 100%|██████████| 140/140 [00:01<00:00, 95.81it/s]\n",
      "[4 / 30]   Val: Loss = 0.49700, Tags accuracy = 93.49%, Intents accuracy = 91.00%: 100%|██████████| 4/4 [00:00<00:00, 90.97it/s]\n",
      "[5 / 30] Train: Loss = 0.35685, Tags accuracy = 94.56%, Intents accuracy = 93.46%: 100%|██████████| 140/140 [00:01<00:00, 121.48it/s]\n",
      "[5 / 30]   Val: Loss = 0.37201, Tags accuracy = 94.90%, Intents accuracy = 92.20%: 100%|██████████| 4/4 [00:00<00:00, 83.07it/s]\n",
      "[6 / 30] Train: Loss = 0.28028, Tags accuracy = 95.75%, Intents accuracy = 95.13%: 100%|██████████| 140/140 [00:01<00:00, 122.02it/s]\n",
      "[6 / 30]   Val: Loss = 0.33925, Tags accuracy = 95.63%, Intents accuracy = 93.00%: 100%|██████████| 4/4 [00:00<00:00, 87.42it/s]\n",
      "[7 / 30] Train: Loss = 0.23016, Tags accuracy = 96.60%, Intents accuracy = 96.11%: 100%|██████████| 140/140 [00:01<00:00, 121.46it/s]\n",
      "[7 / 30]   Val: Loss = 0.26677, Tags accuracy = 96.09%, Intents accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 89.33it/s]\n",
      "[8 / 30] Train: Loss = 0.17976, Tags accuracy = 97.09%, Intents accuracy = 97.36%: 100%|██████████| 140/140 [00:01<00:00, 118.01it/s]\n",
      "[8 / 30]   Val: Loss = 0.24793, Tags accuracy = 96.56%, Intents accuracy = 96.00%: 100%|██████████| 4/4 [00:00<00:00, 84.79it/s]\n",
      "[9 / 30] Train: Loss = 0.15122, Tags accuracy = 97.47%, Intents accuracy = 97.70%: 100%|██████████| 140/140 [00:01<00:00, 120.24it/s]\n",
      "[9 / 30]   Val: Loss = 0.23811, Tags accuracy = 96.84%, Intents accuracy = 95.80%: 100%|██████████| 4/4 [00:00<00:00, 88.15it/s]\n",
      "[10 / 30] Train: Loss = 0.13409, Tags accuracy = 97.83%, Intents accuracy = 97.68%: 100%|██████████| 140/140 [00:01<00:00, 121.86it/s]\n",
      "[10 / 30]   Val: Loss = 0.23548, Tags accuracy = 97.05%, Intents accuracy = 95.80%: 100%|██████████| 4/4 [00:00<00:00, 92.97it/s]\n",
      "[11 / 30] Train: Loss = 0.11443, Tags accuracy = 98.17%, Intents accuracy = 98.24%: 100%|██████████| 140/140 [00:01<00:00, 119.38it/s]\n",
      "[11 / 30]   Val: Loss = 0.21972, Tags accuracy = 97.32%, Intents accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 96.57it/s]\n",
      "[12 / 30] Train: Loss = 0.09524, Tags accuracy = 98.36%, Intents accuracy = 98.70%: 100%|██████████| 140/140 [00:01<00:00, 122.15it/s]\n",
      "[12 / 30]   Val: Loss = 0.21051, Tags accuracy = 97.42%, Intents accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 92.43it/s] \n",
      "[13 / 30] Train: Loss = 0.08034, Tags accuracy = 98.46%, Intents accuracy = 98.86%: 100%|██████████| 140/140 [00:01<00:00, 108.95it/s]\n",
      "[13 / 30]   Val: Loss = 0.20956, Tags accuracy = 97.60%, Intents accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 91.03it/s]\n",
      "[14 / 30] Train: Loss = 0.07060, Tags accuracy = 98.66%, Intents accuracy = 99.13%: 100%|██████████| 140/140 [00:01<00:00, 102.80it/s]\n",
      "[14 / 30]   Val: Loss = 0.19854, Tags accuracy = 97.79%, Intents accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 78.91it/s]\n",
      "[15 / 30] Train: Loss = 0.05677, Tags accuracy = 98.77%, Intents accuracy = 99.37%: 100%|██████████| 140/140 [00:01<00:00, 98.95it/s] \n",
      "[15 / 30]   Val: Loss = 0.18883, Tags accuracy = 97.74%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 100.96it/s]\n",
      "[16 / 30] Train: Loss = 0.04714, Tags accuracy = 98.87%, Intents accuracy = 99.64%: 100%|██████████| 140/140 [00:01<00:00, 117.72it/s]\n",
      "[16 / 30]   Val: Loss = 0.20268, Tags accuracy = 97.93%, Intents accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 92.87it/s]\n",
      "[17 / 30] Train: Loss = 0.05534, Tags accuracy = 98.97%, Intents accuracy = 99.02%: 100%|██████████| 140/140 [00:01<00:00, 122.43it/s]\n",
      "[17 / 30]   Val: Loss = 0.19951, Tags accuracy = 97.86%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 90.50it/s]\n",
      "[18 / 30] Train: Loss = 0.04357, Tags accuracy = 99.12%, Intents accuracy = 99.51%: 100%|██████████| 140/140 [00:01<00:00, 117.19it/s]\n",
      "[18 / 30]   Val: Loss = 0.18910, Tags accuracy = 97.93%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 80.97it/s]\n",
      "[19 / 30] Train: Loss = 0.03777, Tags accuracy = 99.19%, Intents accuracy = 99.55%: 100%|██████████| 140/140 [00:01<00:00, 119.21it/s]\n",
      "[19 / 30]   Val: Loss = 0.19423, Tags accuracy = 97.98%, Intents accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 77.94it/s]\n",
      "[20 / 30] Train: Loss = 0.02967, Tags accuracy = 99.21%, Intents accuracy = 99.80%: 100%|██████████| 140/140 [00:01<00:00, 120.12it/s]\n",
      "[20 / 30]   Val: Loss = 0.18932, Tags accuracy = 98.05%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 88.54it/s]\n",
      "[21 / 30] Train: Loss = 0.02380, Tags accuracy = 99.36%, Intents accuracy = 99.82%: 100%|██████████| 140/140 [00:01<00:00, 116.76it/s]\n",
      "[21 / 30]   Val: Loss = 0.19246, Tags accuracy = 98.05%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 89.23it/s]\n",
      "[22 / 30] Train: Loss = 0.02809, Tags accuracy = 99.42%, Intents accuracy = 99.67%: 100%|██████████| 140/140 [00:01<00:00, 116.21it/s]\n",
      "[22 / 30]   Val: Loss = 0.22401, Tags accuracy = 98.04%, Intents accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 83.79it/s]\n",
      "[23 / 30] Train: Loss = 0.02452, Tags accuracy = 99.41%, Intents accuracy = 99.80%: 100%|██████████| 140/140 [00:01<00:00, 113.83it/s]\n",
      "[23 / 30]   Val: Loss = 0.20192, Tags accuracy = 98.07%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 82.33it/s]\n",
      "[24 / 30] Train: Loss = 0.01664, Tags accuracy = 99.49%, Intents accuracy = 99.96%: 100%|██████████| 140/140 [00:01<00:00, 93.24it/s]\n",
      "[24 / 30]   Val: Loss = 0.20117, Tags accuracy = 98.02%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 70.89it/s]\n",
      "[25 / 30] Train: Loss = 0.01725, Tags accuracy = 99.56%, Intents accuracy = 99.89%: 100%|██████████| 140/140 [00:01<00:00, 91.62it/s]\n",
      "[25 / 30]   Val: Loss = 0.19090, Tags accuracy = 98.04%, Intents accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 71.31it/s]\n",
      "[26 / 30] Train: Loss = 0.01503, Tags accuracy = 99.59%, Intents accuracy = 99.93%: 100%|██████████| 140/140 [00:01<00:00, 110.63it/s]\n",
      "[26 / 30]   Val: Loss = 0.20132, Tags accuracy = 98.04%, Intents accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 88.34it/s]\n",
      "[27 / 30] Train: Loss = 0.02453, Tags accuracy = 99.56%, Intents accuracy = 99.58%: 100%|██████████| 140/140 [00:01<00:00, 118.37it/s]\n",
      "[27 / 30]   Val: Loss = 0.20485, Tags accuracy = 98.04%, Intents accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 87.40it/s]\n",
      "[28 / 30] Train: Loss = 0.02343, Tags accuracy = 99.61%, Intents accuracy = 99.73%: 100%|██████████| 140/140 [00:01<00:00, 115.13it/s]\n",
      "[28 / 30]   Val: Loss = 0.20178, Tags accuracy = 98.05%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 87.78it/s]\n",
      "[29 / 30] Train: Loss = 0.01736, Tags accuracy = 99.60%, Intents accuracy = 99.75%: 100%|██████████| 140/140 [00:01<00:00, 114.23it/s]\n",
      "[29 / 30]   Val: Loss = 0.18719, Tags accuracy = 98.18%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 88.19it/s]\n",
      "[30 / 30] Train: Loss = 0.01483, Tags accuracy = 99.61%, Intents accuracy = 99.84%: 100%|██████████| 140/140 [00:01<00:00, 112.62it/s]\n",
      "[30 / 30]   Val: Loss = 0.17991, Tags accuracy = 98.16%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 87.01it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
    "                    tags_count=len(tags_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = SharedModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlTbVSOezMD7",
    "outputId": "1a8ece5a-7cc1-4da4-f225-099c499dc861"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.35534, Tags accuracy = 97.32%, Intents accuracy = 94.85%: 100%|██████████| 7/7 [00:00<00:00, 96.77it/s] \n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-6XO9lsyhJc",
    "outputId": "5b847de6-d9bb-4fa8-be04-76b80f3d76b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 93.84%, Recall = 93.41%, F1 = 93.62%\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "def eval_tagger(model, test_iter):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iter:\n",
    "            pred = model.forward(batch.tokens.transpose(0, 1))[0].transpose(1, 2).max(dim=1)[1].cpu().tolist()\n",
    "            true = batch.tags.transpose(0, 1).cpu().tolist()\n",
    "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
    "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in true])\n",
    "\n",
    "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
    "\n",
    "eval_tagger(model, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAqVyqZ_SXxc"
   },
   "source": [
    " ## Асинхронное обучение\n",
    "\n",
    "Идея описана в статье [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](http://aclweb.org/anthology/N18-2050).\n",
    "\n",
    "<img src=\"https://i.ibb.co/qrgVSqF/2018-11-27-2-11-17.png\" width=\"600\"/>\n",
    "\n",
    "Основное отличие от того, что уже реализовали в том, в каком порядке все оптимизируется. Вместо объединенного обучения всех слоев, сети для теггера и для классификатора обучаются отдельно.\n",
    "\n",
    "На каждом шаге обучения генерируются последовательности скрытых состояний $h^1$ и $h^2$ - для классификатора и для теггера.\n",
    "\n",
    "Дальше сначала считаются потери от предсказания интента и делается шаг оптимизатора, а затем потери от предсказания теггов - и опять шаг оптимизатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fadD_b4Lb5PW"
   },
   "source": [
    "#### **Задание 3.1**\n",
    "Реализуйте асинхронное обучение совместной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLlVOYfG-dRY"
   },
   "outputs": [],
   "source": [
    "class AsyncSharedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=65,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        # intents\n",
    "        self.int_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.drp = nn.Dropout(0.2)\n",
    "        self.int_lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=True)\n",
    "        self.int_linear = nn.Linear(2*lstm_hidden_dim, intents_count)\n",
    "\n",
    "        self.tag_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.tag_lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=True)\n",
    "        self.tag_linear = nn.Linear(2*lstm_hidden_dim, tags_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # YOUR CODE HERE\n",
    "        #1) intents\n",
    "        int_proj = self.int_emb(inputs)\n",
    "        int_otp, (int_hid, _) = self.int_lstm(int_proj)\n",
    "        int_hid = torch.cat((int_hid[0], int_hid[1]), dim=1)\n",
    "        int_hid = self.drp(int_hid)\n",
    "        intent_output = self.int_linear(int_hid)\n",
    "\n",
    "        #2) tags\n",
    "        tag_proj = self.int_emb(inputs)\n",
    "        tag_otp, (tag_hid, _) = self.int_lstm(tag_proj)\n",
    "        tag_hid = torch.cat((tag_hid[0], tag_hid[1]), dim=1)\n",
    "        tag_otp = self.drp(tag_otp)\n",
    "        tag_output = self.tag_linear(tag_otp)\n",
    "        return tag_output, intent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEYVn6IXBRiR"
   },
   "outputs": [],
   "source": [
    "class AsyncSharedModelTrainer():\n",
    "    def __init__(self, model, criterion, tags_optimizer, intent_optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.tags_optimizer = tags_optimizer\n",
    "        self.intent_optimizer = intent_optimizer\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        self.epoch_loss = 0\n",
    "        self.tag_correct_count, self.tag_total_count = 0, 0\n",
    "        self.intent_correct_count, self.intent_total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        return '{:>5s} Loss = {:.5f}, Tags accuracy = {:.2%}, Intents accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.tag_correct_count / self.tag_total_count, \n",
    "            self.intent_correct_count / self.intent_total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        # YOUR CODE HERE\n",
    "        tokens = batch.tokens.transpose(0,1)\n",
    "        tag_logits, int_logits = self.model(tokens)\n",
    "        # intents\n",
    "        int_loss = self.criterion(int_logits, batch.intent)\n",
    "        int_pred = torch.max(int_logits, dim=1).indices\n",
    "        self.intent_correct_count += torch.sum(int_pred==batch.intent).item()\n",
    "        self.intent_total_count += batch.intent.size()[0]\n",
    "        #tags\n",
    "        tag_pred = torch.max(tag_logits, dim=2).indices\n",
    "        tag_logits = tag_logits.transpose(1,2)\n",
    "        tags = batch.tags.transpose(0,1)\n",
    "        tag_loss = self.criterion(tag_logits, tags)\n",
    "        self.tag_correct_count += torch.sum(tag_pred==tags).item() - torch.sum(tags==0).item()\n",
    "        self.tag_total_count += torch.sum(tags!=0).item()\n",
    "        #comm\n",
    "        if self.is_train:\n",
    "            self.intent_optimizer.zero_grad()\n",
    "            self.tags_optimizer.zero_grad()\n",
    "            int_loss.backward(retain_graph=True)\n",
    "            tag_loss.backward(retain_graph=True)\n",
    "            self.intent_optimizer.step()\n",
    "            self.tags_optimizer.step()\n",
    "        self.epoch_loss += int_loss.item() + tag_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMNscGmZ4APl"
   },
   "source": [
    "Затем их нужно передать в отдельные оптимизаторы и учить отдельно.\n",
    "\n",
    "*Еще, может быть, пригодится retain_graph параметр метода backward()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmMt811LBUXb",
    "outputId": "f6e71242-5e6c-4deb-ca94-c3e2b033b1b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 2.25521, Tags accuracy = 56.62%, Intents accuracy = 74.23%: 100%|██████████| 140/140 [00:01<00:00, 99.06it/s] \n",
      "[1 / 30]   Val: Loss = 1.27366, Tags accuracy = 77.31%, Intents accuracy = 79.20%: 100%|██████████| 4/4 [00:00<00:00, 84.40it/s]\n",
      "[2 / 30] Train: Loss = 0.94051, Tags accuracy = 83.91%, Intents accuracy = 85.57%: 100%|██████████| 140/140 [00:01<00:00, 105.06it/s]\n",
      "[2 / 30]   Val: Loss = 0.76781, Tags accuracy = 88.06%, Intents accuracy = 86.80%: 100%|██████████| 4/4 [00:00<00:00, 87.98it/s]\n",
      "[3 / 30] Train: Loss = 0.54218, Tags accuracy = 91.24%, Intents accuracy = 91.76%: 100%|██████████| 140/140 [00:01<00:00, 105.12it/s]\n",
      "[3 / 30]   Val: Loss = 0.46966, Tags accuracy = 91.76%, Intents accuracy = 90.20%: 100%|██████████| 4/4 [00:00<00:00, 78.59it/s]\n",
      "[4 / 30] Train: Loss = 0.36085, Tags accuracy = 94.02%, Intents accuracy = 94.37%: 100%|██████████| 140/140 [00:01<00:00, 91.26it/s]\n",
      "[4 / 30]   Val: Loss = 0.35633, Tags accuracy = 94.00%, Intents accuracy = 93.00%: 100%|██████████| 4/4 [00:00<00:00, 78.80it/s]\n",
      "[5 / 30] Train: Loss = 0.26629, Tags accuracy = 95.78%, Intents accuracy = 95.65%: 100%|██████████| 140/140 [00:01<00:00, 86.42it/s]\n",
      "[5 / 30]   Val: Loss = 0.30940, Tags accuracy = 95.27%, Intents accuracy = 94.20%: 100%|██████████| 4/4 [00:00<00:00, 62.84it/s]\n",
      "[6 / 30] Train: Loss = 0.19471, Tags accuracy = 96.88%, Intents accuracy = 97.21%: 100%|██████████| 140/140 [00:01<00:00, 86.43it/s]\n",
      "[6 / 30]   Val: Loss = 0.25652, Tags accuracy = 96.09%, Intents accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 80.52it/s]\n",
      "[7 / 30] Train: Loss = 0.14463, Tags accuracy = 97.54%, Intents accuracy = 98.12%: 100%|██████████| 140/140 [00:01<00:00, 101.92it/s]\n",
      "[7 / 30]   Val: Loss = 0.21869, Tags accuracy = 96.51%, Intents accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 82.51it/s]\n",
      "[8 / 30] Train: Loss = 0.11606, Tags accuracy = 98.06%, Intents accuracy = 98.33%: 100%|██████████| 140/140 [00:01<00:00, 102.21it/s]\n",
      "[8 / 30]   Val: Loss = 0.20445, Tags accuracy = 97.02%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 81.47it/s]\n",
      "[9 / 30] Train: Loss = 0.08502, Tags accuracy = 98.43%, Intents accuracy = 99.06%: 100%|██████████| 140/140 [00:01<00:00, 104.01it/s]\n",
      "[9 / 30]   Val: Loss = 0.19325, Tags accuracy = 97.09%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 90.40it/s]\n",
      "[10 / 30] Train: Loss = 0.06590, Tags accuracy = 98.68%, Intents accuracy = 99.40%: 100%|██████████| 140/140 [00:01<00:00, 99.67it/s]\n",
      "[10 / 30]   Val: Loss = 0.18936, Tags accuracy = 97.30%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 80.37it/s]\n",
      "[11 / 30] Train: Loss = 0.05029, Tags accuracy = 98.91%, Intents accuracy = 99.62%: 100%|██████████| 140/140 [00:01<00:00, 101.15it/s]\n",
      "[11 / 30]   Val: Loss = 0.19168, Tags accuracy = 97.44%, Intents accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 84.93it/s]\n",
      "[12 / 30] Train: Loss = 0.04310, Tags accuracy = 99.08%, Intents accuracy = 99.62%: 100%|██████████| 140/140 [00:01<00:00, 103.67it/s]\n",
      "[12 / 30]   Val: Loss = 0.17817, Tags accuracy = 97.48%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 79.62it/s]\n",
      "[13 / 30] Train: Loss = 0.03544, Tags accuracy = 99.23%, Intents accuracy = 99.71%: 100%|██████████| 140/140 [00:01<00:00, 92.70it/s]\n",
      "[13 / 30]   Val: Loss = 0.18012, Tags accuracy = 97.69%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 71.31it/s]\n",
      "[14 / 30] Train: Loss = 0.02709, Tags accuracy = 99.41%, Intents accuracy = 99.84%: 100%|██████████| 140/140 [00:01<00:00, 88.58it/s]\n",
      "[14 / 30]   Val: Loss = 0.16681, Tags accuracy = 97.69%, Intents accuracy = 97.80%: 100%|██████████| 4/4 [00:00<00:00, 59.16it/s]\n",
      "[15 / 30] Train: Loss = 0.02237, Tags accuracy = 99.48%, Intents accuracy = 99.93%: 100%|██████████| 140/140 [00:01<00:00, 81.14it/s]\n",
      "[15 / 30]   Val: Loss = 0.16639, Tags accuracy = 97.84%, Intents accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 75.55it/s]\n",
      "[16 / 30] Train: Loss = 0.01941, Tags accuracy = 99.61%, Intents accuracy = 99.91%: 100%|██████████| 140/140 [00:01<00:00, 100.93it/s]\n",
      "[16 / 30]   Val: Loss = 0.18022, Tags accuracy = 97.90%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 79.20it/s]\n",
      "[17 / 30] Train: Loss = 0.01679, Tags accuracy = 99.61%, Intents accuracy = 99.93%: 100%|██████████| 140/140 [00:01<00:00, 100.25it/s]\n",
      "[17 / 30]   Val: Loss = 0.17799, Tags accuracy = 97.84%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 87.33it/s]\n",
      "[18 / 30] Train: Loss = 0.01277, Tags accuracy = 99.69%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 100.86it/s]\n",
      "[18 / 30]   Val: Loss = 0.16921, Tags accuracy = 98.02%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 87.67it/s]\n",
      "[19 / 30] Train: Loss = 0.01054, Tags accuracy = 99.75%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 103.12it/s]\n",
      "[19 / 30]   Val: Loss = 0.17047, Tags accuracy = 97.98%, Intents accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 77.91it/s]\n",
      "[20 / 30] Train: Loss = 0.03933, Tags accuracy = 99.73%, Intents accuracy = 99.24%: 100%|██████████| 140/140 [00:01<00:00, 100.73it/s]\n",
      "[20 / 30]   Val: Loss = 0.18690, Tags accuracy = 97.83%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 81.65it/s]\n",
      "[21 / 30] Train: Loss = 0.01642, Tags accuracy = 99.80%, Intents accuracy = 99.80%: 100%|██████████| 140/140 [00:01<00:00, 100.05it/s]\n",
      "[21 / 30]   Val: Loss = 0.16676, Tags accuracy = 97.86%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 84.86it/s]\n",
      "[22 / 30] Train: Loss = 0.01269, Tags accuracy = 99.84%, Intents accuracy = 99.87%: 100%|██████████| 140/140 [00:01<00:00, 96.93it/s]\n",
      "[22 / 30]   Val: Loss = 0.16932, Tags accuracy = 97.97%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 72.16it/s]\n",
      "[23 / 30] Train: Loss = 0.00792, Tags accuracy = 99.88%, Intents accuracy = 99.96%: 100%|██████████| 140/140 [00:01<00:00, 91.25it/s]\n",
      "[23 / 30]   Val: Loss = 0.16358, Tags accuracy = 98.09%, Intents accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 79.09it/s]\n",
      "[24 / 30] Train: Loss = 0.00566, Tags accuracy = 99.90%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 86.21it/s]\n",
      "[24 / 30]   Val: Loss = 0.16126, Tags accuracy = 98.07%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 62.56it/s]\n",
      "[25 / 30] Train: Loss = 0.00532, Tags accuracy = 99.92%, Intents accuracy = 99.98%: 100%|██████████| 140/140 [00:01<00:00, 89.88it/s]\n",
      "[25 / 30]   Val: Loss = 0.16675, Tags accuracy = 98.05%, Intents accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 76.02it/s]\n",
      "[26 / 30] Train: Loss = 0.00436, Tags accuracy = 99.92%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 101.74it/s]\n",
      "[26 / 30]   Val: Loss = 0.16251, Tags accuracy = 98.14%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 78.24it/s]\n",
      "[27 / 30] Train: Loss = 0.00373, Tags accuracy = 99.95%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 101.01it/s]\n",
      "[27 / 30]   Val: Loss = 0.16719, Tags accuracy = 98.16%, Intents accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 91.22it/s]\n",
      "[28 / 30] Train: Loss = 0.00339, Tags accuracy = 99.95%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 102.22it/s]\n",
      "[28 / 30]   Val: Loss = 0.16726, Tags accuracy = 98.21%, Intents accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 81.20it/s]\n",
      "[29 / 30] Train: Loss = 0.00291, Tags accuracy = 99.95%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 101.43it/s]\n",
      "[29 / 30]   Val: Loss = 0.17533, Tags accuracy = 98.18%, Intents accuracy = 97.80%: 100%|██████████| 4/4 [00:00<00:00, 80.67it/s]\n",
      "[30 / 30] Train: Loss = 0.00272, Tags accuracy = 99.96%, Intents accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 99.06it/s]\n",
      "[30 / 30]   Val: Loss = 0.17407, Tags accuracy = 98.16%, Intents accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 88.68it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AsyncSharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab),\n",
    "                         tags_count=len(tags_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "tags_parameters = [param for name, param in model.named_parameters() if not 'int_' in name]\n",
    "intent_parameters = [param for name, param in model.named_parameters() if not 'tag_' in name]\n",
    "tags_optimizer = optim.Adam(tags_parameters)\n",
    "intent_optimizer = optim.Adam(intent_parameters)\n",
    "trainer = AsyncSharedModelTrainer(model, criterion, tags_optimizer, intent_optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbroXzacJJlv",
    "outputId": "1a903dcc-8cb7-43a5-cf4d-9d53be9c3277"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.38197, Tags accuracy = 97.20%, Intents accuracy = 94.74%: 100%|██████████| 7/7 [00:00<00:00, 84.07it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnMw5L4iG5Io",
    "outputId": "2d43f021-6131-433e-86c0-8c133a3904da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 93.53%, Recall = 93.27%, F1 = 93.40%\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "def eval_tagger(model, test_iter):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iter:\n",
    "            pred = model.forward(batch.tokens.transpose(0, 1))[0].transpose(1, 2).max(dim=1)[1].cpu().tolist()\n",
    "            pred_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in pred])\n",
    "            true_seqs.extend([\" \".join([tags_field.vocab.itos[elem] for elem in l if elem != 0]) for l in batch.tags.transpose(0, 1).cpu().tolist()])\n",
    "\n",
    "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
    "\n",
    "eval_tagger(model, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE-5oyMUU40L"
   },
   "source": [
    "#### **Задание 3.2**\n",
    "Посмотрите на параметры в статье и попробуйте добиться похожего качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z77TqFTlkerA"
   },
   "source": [
    "статья: https://www.csie.ntu.edu.tw/~yvchen/doc/NAACL18_SlotGated.pdf\n",
    "\n",
    "Хорошая идея - использовать не просто независимые предсказания тегов, а декодер над ними:\n",
    "\n",
    "архитектура:\n",
    "![](https://i.ibb.co/qrgVSqF/2018-11-27-2-11-17.png =600x)\n",
    "\n",
    "По сути тут добавляется просто еще слой RNN - на этот раз однонаправленной. При этом его вход в случае предсказания тегов - это предыдущий тег, предыдущее скрытое состояние и скрытые состояния из энкодеров теггов и интента. Для интента - простая RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7xU7KeipN0S"
   },
   "source": [
    "##### Интенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slsemqxZpR7M"
   },
   "outputs": [],
   "source": [
    "class IntentRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, emb_dim=64,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.enc_lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.dec_lstm = nn.LSTM(2*lstm_hidden_dim, lstm_hidden_dim, batch_first=True, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim, intents_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # YOUR CODE HERE\n",
    "        emb = self.embedding(inputs)\n",
    "        drp = self.dropout(emb)\n",
    "        enc_ountput, (enc_hidden_state, _) = self.enc_lstm(drp)\n",
    "        hidden = torch.cat((enc_hidden_state[0], enc_hidden_state[1]), dim=1)\n",
    "        dec_ountput, (dec_hidden_state, _) = self.dec_lstm(enc_ountput)\n",
    "        output = self.linear(dec_hidden_state[0])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGCx2Tkmpk-s",
    "outputId": "4445648d-0235-4a88-9e30-a71aeb15dcd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 1.24113, Accuracy = 72.71%: 100%|██████████| 140/140 [00:01<00:00, 112.09it/s]\n",
      "[1 / 30]   Val: Loss = 1.25193, Accuracy = 71.40%: 100%|██████████| 4/4 [00:00<00:00, 94.01it/s] \n",
      "[2 / 30] Train: Loss = 1.13294, Accuracy = 73.89%: 100%|██████████| 140/140 [00:01<00:00, 119.55it/s]\n",
      "[2 / 30]   Val: Loss = 1.24894, Accuracy = 71.40%: 100%|██████████| 4/4 [00:00<00:00, 83.27it/s]\n",
      "[3 / 30] Train: Loss = 1.04045, Accuracy = 74.45%: 100%|██████████| 140/140 [00:01<00:00, 120.26it/s]\n",
      "[3 / 30]   Val: Loss = 1.05034, Accuracy = 73.20%: 100%|██████████| 4/4 [00:00<00:00, 95.74it/s]\n",
      "[4 / 30] Train: Loss = 0.85266, Accuracy = 75.97%: 100%|██████████| 140/140 [00:01<00:00, 125.57it/s]\n",
      "[4 / 30]   Val: Loss = 0.93331, Accuracy = 75.40%: 100%|██████████| 4/4 [00:00<00:00, 100.63it/s]\n",
      "[5 / 30] Train: Loss = 0.71674, Accuracy = 81.38%: 100%|██████████| 140/140 [00:01<00:00, 124.21it/s]\n",
      "[5 / 30]   Val: Loss = 0.84196, Accuracy = 78.60%: 100%|██████████| 4/4 [00:00<00:00, 93.91it/s]\n",
      "[6 / 30] Train: Loss = 0.63233, Accuracy = 82.34%: 100%|██████████| 140/140 [00:01<00:00, 125.32it/s]\n",
      "[6 / 30]   Val: Loss = 0.71849, Accuracy = 80.20%: 100%|██████████| 4/4 [00:00<00:00, 95.50it/s]\n",
      "[7 / 30] Train: Loss = 0.53698, Accuracy = 85.51%: 100%|██████████| 140/140 [00:01<00:00, 122.68it/s]\n",
      "[7 / 30]   Val: Loss = 0.64770, Accuracy = 84.40%: 100%|██████████| 4/4 [00:00<00:00, 93.87it/s]\n",
      "[8 / 30] Train: Loss = 0.42699, Accuracy = 88.10%: 100%|██████████| 140/140 [00:01<00:00, 125.91it/s]\n",
      "[8 / 30]   Val: Loss = 0.50436, Accuracy = 85.20%: 100%|██████████| 4/4 [00:00<00:00, 98.64it/s] \n",
      "[9 / 30] Train: Loss = 0.34653, Accuracy = 91.22%: 100%|██████████| 140/140 [00:01<00:00, 115.58it/s]\n",
      "[9 / 30]   Val: Loss = 0.39106, Accuracy = 90.20%: 100%|██████████| 4/4 [00:00<00:00, 90.08it/s]\n",
      "[10 / 30] Train: Loss = 0.27932, Accuracy = 92.41%: 100%|██████████| 140/140 [00:01<00:00, 108.20it/s]\n",
      "[10 / 30]   Val: Loss = 0.43768, Accuracy = 89.00%: 100%|██████████| 4/4 [00:00<00:00, 87.53it/s]\n",
      "[11 / 30] Train: Loss = 0.23687, Accuracy = 93.55%: 100%|██████████| 140/140 [00:01<00:00, 110.41it/s]\n",
      "[11 / 30]   Val: Loss = 0.30468, Accuracy = 91.80%: 100%|██████████| 4/4 [00:00<00:00, 81.30it/s]\n",
      "[12 / 30] Train: Loss = 0.19257, Accuracy = 94.64%: 100%|██████████| 140/140 [00:01<00:00, 100.11it/s]\n",
      "[12 / 30]   Val: Loss = 0.26280, Accuracy = 93.20%: 100%|██████████| 4/4 [00:00<00:00, 74.38it/s]\n",
      "[13 / 30] Train: Loss = 0.16428, Accuracy = 95.76%: 100%|██████████| 140/140 [00:01<00:00, 120.45it/s]\n",
      "[13 / 30]   Val: Loss = 0.20504, Accuracy = 95.60%: 100%|██████████| 4/4 [00:00<00:00, 87.40it/s]\n",
      "[14 / 30] Train: Loss = 0.12670, Accuracy = 96.76%: 100%|██████████| 140/140 [00:01<00:00, 124.00it/s]\n",
      "[14 / 30]   Val: Loss = 0.18996, Accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 93.01it/s]\n",
      "[15 / 30] Train: Loss = 0.10269, Accuracy = 97.43%: 100%|██████████| 140/140 [00:01<00:00, 120.09it/s]\n",
      "[15 / 30]   Val: Loss = 0.19698, Accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 87.18it/s]\n",
      "[16 / 30] Train: Loss = 0.08653, Accuracy = 97.86%: 100%|██████████| 140/140 [00:01<00:00, 119.86it/s]\n",
      "[16 / 30]   Val: Loss = 0.16549, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 89.29it/s]\n",
      "[17 / 30] Train: Loss = 0.08531, Accuracy = 97.88%: 100%|██████████| 140/140 [00:01<00:00, 121.26it/s]\n",
      "[17 / 30]   Val: Loss = 0.18587, Accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 88.52it/s]\n",
      "[18 / 30] Train: Loss = 0.07065, Accuracy = 98.35%: 100%|██████████| 140/140 [00:01<00:00, 121.92it/s]\n",
      "[18 / 30]   Val: Loss = 0.16404, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 92.86it/s]\n",
      "[19 / 30] Train: Loss = 0.05464, Accuracy = 98.79%: 100%|██████████| 140/140 [00:01<00:00, 119.80it/s]\n",
      "[19 / 30]   Val: Loss = 0.20474, Accuracy = 96.00%: 100%|██████████| 4/4 [00:00<00:00, 92.84it/s]\n",
      "[20 / 30] Train: Loss = 0.04803, Accuracy = 98.77%: 100%|██████████| 140/140 [00:01<00:00, 121.90it/s]\n",
      "[20 / 30]   Val: Loss = 0.18690, Accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 101.41it/s]\n",
      "[21 / 30] Train: Loss = 0.04038, Accuracy = 99.04%: 100%|██████████| 140/140 [00:01<00:00, 109.37it/s]\n",
      "[21 / 30]   Val: Loss = 0.17029, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 87.76it/s]\n",
      "[22 / 30] Train: Loss = 0.03991, Accuracy = 99.06%: 100%|██████████| 140/140 [00:01<00:00, 98.76it/s] \n",
      "[22 / 30]   Val: Loss = 0.17993, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 77.65it/s]\n",
      "[23 / 30] Train: Loss = 0.03176, Accuracy = 99.20%: 100%|██████████| 140/140 [00:01<00:00, 93.54it/s]\n",
      "[23 / 30]   Val: Loss = 0.16411, Accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 65.32it/s]\n",
      "[24 / 30] Train: Loss = 0.03232, Accuracy = 99.17%: 100%|██████████| 140/140 [00:01<00:00, 111.62it/s]\n",
      "[24 / 30]   Val: Loss = 0.15653, Accuracy = 97.40%: 100%|██████████| 4/4 [00:00<00:00, 96.29it/s] \n",
      "[25 / 30] Train: Loss = 0.02946, Accuracy = 99.17%: 100%|██████████| 140/140 [00:01<00:00, 120.77it/s]\n",
      "[25 / 30]   Val: Loss = 0.15370, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 88.60it/s]\n",
      "[26 / 30] Train: Loss = 0.02636, Accuracy = 99.26%: 100%|██████████| 140/140 [00:01<00:00, 118.13it/s]\n",
      "[26 / 30]   Val: Loss = 0.16882, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 95.69it/s]\n",
      "[27 / 30] Train: Loss = 0.01772, Accuracy = 99.55%: 100%|██████████| 140/140 [00:01<00:00, 116.36it/s]\n",
      "[27 / 30]   Val: Loss = 0.14308, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 74.32it/s]\n",
      "[28 / 30] Train: Loss = 0.02120, Accuracy = 99.40%: 100%|██████████| 140/140 [00:01<00:00, 117.26it/s]\n",
      "[28 / 30]   Val: Loss = 0.13955, Accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 88.16it/s]\n",
      "[29 / 30] Train: Loss = 0.02099, Accuracy = 99.46%: 100%|██████████| 140/140 [00:01<00:00, 116.84it/s]\n",
      "[29 / 30]   Val: Loss = 0.13623, Accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 83.96it/s]\n",
      "[30 / 30] Train: Loss = 0.01605, Accuracy = 99.58%: 100%|██████████| 140/140 [00:01<00:00, 117.07it/s]\n",
      "[30 / 30]   Val: Loss = 0.14434, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 95.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model = IntentRNNModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = ModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2IxgNPssIDb",
    "outputId": "d7460b78-5a1a-40b7-f1ef-b71ed69bc72f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.32842, Accuracy = 95.18%: 100%|██████████| 7/7 [00:00<00:00, 103.60it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVZzeSn6pF81"
   },
   "source": [
    "##### Теггер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sc7ZVEX3kdmj"
   },
   "outputs": [],
   "source": [
    "class TaggerRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tags_count, emb_dim=64,\n",
    "                 lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.enc_lstm = nn.LSTM(emb_dim, lstm_hidden_dim, batch_first=True,\n",
    "                            num_layers=num_layers, bidirectional=True)\n",
    "        self.dec_lstm = nn.LSTM(2*lstm_hidden_dim, lstm_hidden_dim, batch_first=True, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim, tags_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embedding(inputs)\n",
    "        drp = self.dropout(emb)\n",
    "        enc_ountput, (hidden_state, _) = self.enc_lstm(drp)\n",
    "        dec_ountput, (hidden_state, _) = self.dec_lstm(enc_ountput)\n",
    "        output = self.linear(dec_ountput)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clEN483Llvum",
    "outputId": "86053281-d2d7-49b8-ec2b-ec90d98bf2c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 1.21541, Accuracy = 56.77%: 100%|██████████| 140/140 [00:01<00:00, 118.11it/s]\n",
      "[1 / 30]   Val: Loss = 0.49616, Accuracy = 74.61%: 100%|██████████| 4/4 [00:00<00:00, 95.84it/s]\n",
      "[2 / 30] Train: Loss = 0.47031, Accuracy = 80.55%: 100%|██████████| 140/140 [00:01<00:00, 102.48it/s]\n",
      "[2 / 30]   Val: Loss = 0.28781, Accuracy = 84.01%: 100%|██████████| 4/4 [00:00<00:00, 83.18it/s]\n",
      "[3 / 30] Train: Loss = 0.29098, Accuracy = 88.05%: 100%|██████████| 140/140 [00:01<00:00, 101.25it/s]\n",
      "[3 / 30]   Val: Loss = 0.19691, Accuracy = 90.43%: 100%|██████████| 4/4 [00:00<00:00, 75.38it/s]\n",
      "[4 / 30] Train: Loss = 0.19292, Accuracy = 92.20%: 100%|██████████| 140/140 [00:01<00:00, 91.37it/s]\n",
      "[4 / 30]   Val: Loss = 0.13032, Accuracy = 93.09%: 100%|██████████| 4/4 [00:00<00:00, 78.16it/s]\n",
      "[5 / 30] Train: Loss = 0.13993, Accuracy = 94.28%: 100%|██████████| 140/140 [00:01<00:00, 115.47it/s]\n",
      "[5 / 30]   Val: Loss = 0.10328, Accuracy = 94.69%: 100%|██████████| 4/4 [00:00<00:00, 80.62it/s]\n",
      "[6 / 30] Train: Loss = 0.10341, Accuracy = 95.52%: 100%|██████████| 140/140 [00:01<00:00, 120.43it/s]\n",
      "[6 / 30]   Val: Loss = 0.08140, Accuracy = 95.37%: 100%|██████████| 4/4 [00:00<00:00, 92.30it/s]\n",
      "[7 / 30] Train: Loss = 0.08134, Accuracy = 96.46%: 100%|██████████| 140/140 [00:01<00:00, 116.74it/s]\n",
      "[7 / 30]   Val: Loss = 0.06713, Accuracy = 95.77%: 100%|██████████| 4/4 [00:00<00:00, 92.11it/s]\n",
      "[8 / 30] Train: Loss = 0.06592, Accuracy = 97.21%: 100%|██████████| 140/140 [00:01<00:00, 115.87it/s]\n",
      "[8 / 30]   Val: Loss = 0.06411, Accuracy = 96.76%: 100%|██████████| 4/4 [00:00<00:00, 77.48it/s]\n",
      "[9 / 30] Train: Loss = 0.05317, Accuracy = 97.87%: 100%|██████████| 140/140 [00:01<00:00, 117.28it/s]\n",
      "[9 / 30]   Val: Loss = 0.05008, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 91.63it/s]\n",
      "[10 / 30] Train: Loss = 0.04339, Accuracy = 98.27%: 100%|██████████| 140/140 [00:01<00:00, 119.71it/s]\n",
      "[10 / 30]   Val: Loss = 0.04600, Accuracy = 97.55%: 100%|██████████| 4/4 [00:00<00:00, 95.80it/s]\n",
      "[11 / 30] Train: Loss = 0.03594, Accuracy = 98.58%: 100%|██████████| 140/140 [00:01<00:00, 120.50it/s]\n",
      "[11 / 30]   Val: Loss = 0.03650, Accuracy = 97.93%: 100%|██████████| 4/4 [00:00<00:00, 89.61it/s]\n",
      "[12 / 30] Train: Loss = 0.03018, Accuracy = 98.85%: 100%|██████████| 140/140 [00:01<00:00, 113.77it/s]\n",
      "[12 / 30]   Val: Loss = 0.03567, Accuracy = 98.16%: 100%|██████████| 4/4 [00:00<00:00, 79.77it/s]\n",
      "[13 / 30] Train: Loss = 0.02583, Accuracy = 98.98%: 100%|██████████| 140/140 [00:01<00:00, 100.71it/s]\n",
      "[13 / 30]   Val: Loss = 0.03193, Accuracy = 98.12%: 100%|██████████| 4/4 [00:00<00:00, 84.14it/s]\n",
      "[14 / 30] Train: Loss = 0.02139, Accuracy = 99.19%: 100%|██████████| 140/140 [00:01<00:00, 94.58it/s]\n",
      "[14 / 30]   Val: Loss = 0.03354, Accuracy = 98.44%: 100%|██████████| 4/4 [00:00<00:00, 78.16it/s]\n",
      "[15 / 30] Train: Loss = 0.01757, Accuracy = 99.31%: 100%|██████████| 140/140 [00:01<00:00, 95.23it/s] \n",
      "[15 / 30]   Val: Loss = 0.03051, Accuracy = 98.35%: 100%|██████████| 4/4 [00:00<00:00, 80.33it/s]\n",
      "[16 / 30] Train: Loss = 0.01648, Accuracy = 99.33%: 100%|██████████| 140/140 [00:01<00:00, 114.17it/s]\n",
      "[16 / 30]   Val: Loss = 0.02770, Accuracy = 98.39%: 100%|██████████| 4/4 [00:00<00:00, 84.44it/s]\n",
      "[17 / 30] Train: Loss = 0.01386, Accuracy = 99.45%: 100%|██████████| 140/140 [00:01<00:00, 119.01it/s]\n",
      "[17 / 30]   Val: Loss = 0.02634, Accuracy = 98.46%: 100%|██████████| 4/4 [00:00<00:00, 86.68it/s]\n",
      "[18 / 30] Train: Loss = 0.01166, Accuracy = 99.53%: 100%|██████████| 140/140 [00:01<00:00, 113.01it/s]\n",
      "[18 / 30]   Val: Loss = 0.03021, Accuracy = 98.35%: 100%|██████████| 4/4 [00:00<00:00, 88.06it/s]\n",
      "[19 / 30] Train: Loss = 0.01110, Accuracy = 99.53%: 100%|██████████| 140/140 [00:01<00:00, 117.20it/s]\n",
      "[19 / 30]   Val: Loss = 0.02667, Accuracy = 98.40%: 100%|██████████| 4/4 [00:00<00:00, 89.45it/s]\n",
      "[20 / 30] Train: Loss = 0.00933, Accuracy = 99.67%: 100%|██████████| 140/140 [00:01<00:00, 118.07it/s]\n",
      "[20 / 30]   Val: Loss = 0.02732, Accuracy = 98.32%: 100%|██████████| 4/4 [00:00<00:00, 98.24it/s] \n",
      "[21 / 30] Train: Loss = 0.00853, Accuracy = 99.68%: 100%|██████████| 140/140 [00:01<00:00, 115.79it/s]\n",
      "[21 / 30]   Val: Loss = 0.02638, Accuracy = 98.49%: 100%|██████████| 4/4 [00:00<00:00, 80.94it/s]\n",
      "[22 / 30] Train: Loss = 0.00787, Accuracy = 99.68%: 100%|██████████| 140/140 [00:01<00:00, 115.84it/s]\n",
      "[22 / 30]   Val: Loss = 0.02416, Accuracy = 98.46%: 100%|██████████| 4/4 [00:00<00:00, 77.91it/s]\n",
      "[23 / 30] Train: Loss = 0.00671, Accuracy = 99.76%: 100%|██████████| 140/140 [00:01<00:00, 105.62it/s]\n",
      "[23 / 30]   Val: Loss = 0.02510, Accuracy = 98.60%: 100%|██████████| 4/4 [00:00<00:00, 71.89it/s]\n",
      "[24 / 30] Train: Loss = 0.00604, Accuracy = 99.77%: 100%|██████████| 140/140 [00:01<00:00, 104.11it/s]\n",
      "[24 / 30]   Val: Loss = 0.02393, Accuracy = 98.63%: 100%|██████████| 4/4 [00:00<00:00, 67.57it/s]\n",
      "[25 / 30] Train: Loss = 0.00507, Accuracy = 99.82%: 100%|██████████| 140/140 [00:01<00:00, 91.48it/s]\n",
      "[25 / 30]   Val: Loss = 0.02634, Accuracy = 98.54%: 100%|██████████| 4/4 [00:00<00:00, 75.09it/s]\n",
      "[26 / 30] Train: Loss = 0.00473, Accuracy = 99.82%: 100%|██████████| 140/140 [00:01<00:00, 99.24it/s] \n",
      "[26 / 30]   Val: Loss = 0.02415, Accuracy = 98.60%: 100%|██████████| 4/4 [00:00<00:00, 83.29it/s]\n",
      "[27 / 30] Train: Loss = 0.00416, Accuracy = 99.85%: 100%|██████████| 140/140 [00:01<00:00, 117.30it/s]\n",
      "[27 / 30]   Val: Loss = 0.02546, Accuracy = 98.61%: 100%|██████████| 4/4 [00:00<00:00, 89.16it/s]\n",
      "[28 / 30] Train: Loss = 0.00386, Accuracy = 99.87%: 100%|██████████| 140/140 [00:01<00:00, 113.10it/s]\n",
      "[28 / 30]   Val: Loss = 0.02276, Accuracy = 98.65%: 100%|██████████| 4/4 [00:00<00:00, 80.82it/s]\n",
      "[29 / 30] Train: Loss = 0.00312, Accuracy = 99.92%: 100%|██████████| 140/140 [00:01<00:00, 116.90it/s]\n",
      "[29 / 30]   Val: Loss = 0.02258, Accuracy = 98.63%: 100%|██████████| 4/4 [00:00<00:00, 93.79it/s]\n",
      "[30 / 30] Train: Loss = 0.00345, Accuracy = 99.88%: 100%|██████████| 140/140 [00:01<00:00, 115.49it/s]\n",
      "[30 / 30]   Val: Loss = 0.02266, Accuracy = 98.61%: 100%|██████████| 4/4 [00:00<00:00, 80.08it/s]\n"
     ]
    }
   ],
   "source": [
    "model = TaggerRNNModel(vocab_size=len(tokens_field.vocab), tags_count=len(tags_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = TagModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2a_sMZcokTw",
    "outputId": "ef1da321-dd99-40e3-bccf-6a4c6a8adf16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.06675, Accuracy = 97.34%: 100%|██████████| 7/7 [00:00<00:00, 100.88it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRFlIyJQV4Wu"
   },
   "source": [
    "#### **Задание 4**\n",
    "Посмотрите результаты на SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DM5ytngyPM6",
    "outputId": "846a295c-1643-4fe3-fe82-1b788ad313bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 0.37172, Accuracy = 89.81%: 100%|██████████| 409/409 [00:02<00:00, 177.50it/s]\n",
      "[1 / 30]   Val: Loss = 0.13436, Accuracy = 96.57%: 100%|██████████| 6/6 [00:00<00:00, 213.86it/s]\n",
      "[2 / 30] Train: Loss = 0.08968, Accuracy = 97.25%: 100%|██████████| 409/409 [00:02<00:00, 185.55it/s]\n",
      "[2 / 30]   Val: Loss = 0.10900, Accuracy = 96.71%: 100%|██████████| 6/6 [00:00<00:00, 212.58it/s]\n",
      "[3 / 30] Train: Loss = 0.05022, Accuracy = 98.42%: 100%|██████████| 409/409 [00:02<00:00, 182.64it/s]\n",
      "[3 / 30]   Val: Loss = 0.08238, Accuracy = 97.29%: 100%|██████████| 6/6 [00:00<00:00, 208.94it/s]\n",
      "[4 / 30] Train: Loss = 0.03203, Accuracy = 99.08%: 100%|██████████| 409/409 [00:02<00:00, 186.51it/s]\n",
      "[4 / 30]   Val: Loss = 0.11307, Accuracy = 96.43%: 100%|██████████| 6/6 [00:00<00:00, 221.44it/s]\n",
      "[5 / 30] Train: Loss = 0.02239, Accuracy = 99.30%: 100%|██████████| 409/409 [00:02<00:00, 185.71it/s]\n",
      "[5 / 30]   Val: Loss = 0.07490, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 211.77it/s]\n",
      "[6 / 30] Train: Loss = 0.01420, Accuracy = 99.60%: 100%|██████████| 409/409 [00:02<00:00, 192.01it/s]\n",
      "[6 / 30]   Val: Loss = 0.09301, Accuracy = 97.00%: 100%|██████████| 6/6 [00:00<00:00, 213.37it/s]\n",
      "[7 / 30] Train: Loss = 0.00750, Accuracy = 99.82%: 100%|██████████| 409/409 [00:02<00:00, 189.86it/s]\n",
      "[7 / 30]   Val: Loss = 0.07654, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 234.41it/s]\n",
      "[8 / 30] Train: Loss = 0.00794, Accuracy = 99.81%: 100%|██████████| 409/409 [00:02<00:00, 189.54it/s]\n",
      "[8 / 30]   Val: Loss = 0.08321, Accuracy = 97.71%: 100%|██████████| 6/6 [00:00<00:00, 228.60it/s]\n",
      "[9 / 30] Train: Loss = 0.00260, Accuracy = 99.98%: 100%|██████████| 409/409 [00:02<00:00, 185.65it/s]\n",
      "[9 / 30]   Val: Loss = 0.10755, Accuracy = 97.29%: 100%|██████████| 6/6 [00:00<00:00, 214.76it/s]\n",
      "[10 / 30] Train: Loss = 0.00107, Accuracy = 99.99%: 100%|██████████| 409/409 [00:02<00:00, 192.43it/s]\n",
      "[10 / 30]   Val: Loss = 0.10881, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 234.70it/s]\n",
      "[11 / 30] Train: Loss = 0.00055, Accuracy = 99.99%: 100%|██████████| 409/409 [00:02<00:00, 190.74it/s]\n",
      "[11 / 30]   Val: Loss = 0.12022, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 219.86it/s]\n",
      "[12 / 30] Train: Loss = 0.00026, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 191.44it/s]\n",
      "[12 / 30]   Val: Loss = 0.11458, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 241.02it/s]\n",
      "[13 / 30] Train: Loss = 0.00017, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 190.37it/s]\n",
      "[13 / 30]   Val: Loss = 0.13121, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 225.60it/s]\n",
      "[14 / 30] Train: Loss = 0.00014, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 185.90it/s]\n",
      "[14 / 30]   Val: Loss = 0.13262, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 215.78it/s]\n",
      "[15 / 30] Train: Loss = 0.00010, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 189.14it/s]\n",
      "[15 / 30]   Val: Loss = 0.12637, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 244.89it/s]\n",
      "[16 / 30] Train: Loss = 0.00007, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 191.53it/s]\n",
      "[16 / 30]   Val: Loss = 0.16059, Accuracy = 97.43%: 100%|██████████| 6/6 [00:00<00:00, 244.98it/s]\n",
      "[17 / 30] Train: Loss = 0.00005, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 188.54it/s]\n",
      "[17 / 30]   Val: Loss = 0.13463, Accuracy = 97.43%: 100%|██████████| 6/6 [00:00<00:00, 233.40it/s]\n",
      "[18 / 30] Train: Loss = 0.00005, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 186.08it/s]\n",
      "[18 / 30]   Val: Loss = 0.15816, Accuracy = 97.43%: 100%|██████████| 6/6 [00:00<00:00, 213.97it/s]\n",
      "[19 / 30] Train: Loss = 0.00004, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 188.26it/s]\n",
      "[19 / 30]   Val: Loss = 0.13870, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 224.98it/s]\n",
      "[20 / 30] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 180.83it/s]\n",
      "[20 / 30]   Val: Loss = 0.15946, Accuracy = 97.43%: 100%|██████████| 6/6 [00:00<00:00, 228.16it/s]\n",
      "[21 / 30] Train: Loss = 0.00002, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 177.08it/s]\n",
      "[21 / 30]   Val: Loss = 0.16956, Accuracy = 97.57%: 100%|██████████| 6/6 [00:00<00:00, 229.30it/s]\n",
      "[22 / 30] Train: Loss = 0.00967, Accuracy = 99.72%: 100%|██████████| 409/409 [00:02<00:00, 185.60it/s]\n",
      "[22 / 30]   Val: Loss = 0.16298, Accuracy = 96.29%: 100%|██████████| 6/6 [00:00<00:00, 230.32it/s]\n",
      "[23 / 30] Train: Loss = 0.01674, Accuracy = 99.50%: 100%|██████████| 409/409 [00:02<00:00, 185.22it/s]\n",
      "[23 / 30]   Val: Loss = 0.15581, Accuracy = 96.71%: 100%|██████████| 6/6 [00:00<00:00, 226.68it/s]\n",
      "[24 / 30] Train: Loss = 0.00139, Accuracy = 99.97%: 100%|██████████| 409/409 [00:02<00:00, 189.01it/s]\n",
      "[24 / 30]   Val: Loss = 0.15771, Accuracy = 96.86%: 100%|██████████| 6/6 [00:00<00:00, 228.15it/s]\n",
      "[25 / 30] Train: Loss = 0.00086, Accuracy = 99.98%: 100%|██████████| 409/409 [00:02<00:00, 184.49it/s]\n",
      "[25 / 30]   Val: Loss = 0.14272, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 227.24it/s]\n",
      "[26 / 30] Train: Loss = 0.00026, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 183.13it/s]\n",
      "[26 / 30]   Val: Loss = 0.14334, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 216.90it/s]\n",
      "[27 / 30] Train: Loss = 0.00011, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 186.41it/s]\n",
      "[27 / 30]   Val: Loss = 0.15093, Accuracy = 96.86%: 100%|██████████| 6/6 [00:00<00:00, 234.64it/s]\n",
      "[28 / 30] Train: Loss = 0.00007, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 189.78it/s]\n",
      "[28 / 30]   Val: Loss = 0.15105, Accuracy = 97.14%: 100%|██████████| 6/6 [00:00<00:00, 233.04it/s]\n",
      "[29 / 30] Train: Loss = 0.00006, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 188.25it/s]\n",
      "[29 / 30]   Val: Loss = 0.17498, Accuracy = 96.86%: 100%|██████████| 6/6 [00:00<00:00, 216.88it/s]\n",
      "[30 / 30] Train: Loss = 0.00005, Accuracy = 100.00%: 100%|██████████| 409/409 [00:02<00:00, 189.29it/s]\n",
      "[30 / 30]   Val: Loss = 0.16727, Accuracy = 96.71%: 100%|██████████| 6/6 [00:00<00:00, 236.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = IntentClassifierModel(   vocab_size=len(snips_tokens_field.vocab), \n",
    "                              intents_count=len(snips_intent_field.vocab)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trainer = ModelTrainer(model, criterion, optimizer)\n",
    "fit(trainer, snips_train_iter, epochs_count=30, val_iter=snips_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jk1kM08WGDh",
    "outputId": "7a958944-272c-4912-b138-f1950af0f421"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.18891, Accuracy = 96.43%: 100%|██████████| 6/6 [00:00<00:00, 202.75it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, snips_test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NujuoWDU195f"
   },
   "source": [
    "## Async Multi-task Learning for POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9Q0ip3p2a5v"
   },
   "source": [
    "Ещё одна статья: [Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings](https://arxiv.org/pdf/1805.08237.pdf)\n",
    "\n",
    "Архитектура там такая:\n",
    "\n",
    "<img src=\"https://i.ibb.co/0nSX6CC/2018-11-27-9-26-15.png\" width=\"400\"/>\n",
    "\n",
    "Multi-task задача - обучение отдельных классификаторов более низкого уровня (над символами и словами) для предсказания тегов отдельными оптимизаторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyB8YIO6SH9T"
   },
   "source": [
    "## DeepPavlov go_bot\n",
    "\n",
    "http://docs.deeppavlov.ai/en/master/features/skills/go_bot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBonKW_7SSOQ"
   },
   "outputs": [],
   "source": [
    "# !pip install deeppavlov==0.14.0\n",
    "!python -m deeppavlov install gobot_dstc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T12:39:15.606859Z",
     "start_time": "2023-04-13T12:39:15.600272Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "bBh7aB9WSQ3m",
    "outputId": "228223e9-6153-4a56-a30e-61a2fcb8b5c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "bot1 = build_model(configs.go_bot.gobot_dstc2, download=True)\n",
    "\n",
    "bot1(['hi, i want restaurant in the cheap pricerange'])\n",
    "bot1(['bye'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD670nqlWZOM"
   },
   "source": [
    "Поддробные туториалы:\n",
    "\n",
    "Simple: https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/gobot_tutorial.ipynb\n",
    "\n",
    "Extended: https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/gobot_extended_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2x9-j4oz08p"
   },
   "source": [
    "# Дополнительные материалы\n",
    "\n",
    "## Статьи\n",
    "A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling, 2018 [[pdf]](http://aclweb.org/anthology/N18-2050)\n",
    "\n",
    "Slot-Gated Modeling for Joint Slot Filling and Intent Prediction, 2018 [[pdf]](http://aclweb.org/anthology/N18-2118) \n",
    "\n",
    "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings, 2018 [[pdf]](https://arxiv.org/pdf/1805.08237.pdf)\n",
    "\n",
    "BERT for Joint Intent Classification and Slot Filling\n",
    " [[pdf]](https://arxiv.org/pdf/1902.10909.pdf)\n",
    "\n",
    "## Блоги\n",
    "[Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoVaY5nh11w2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
